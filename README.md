# Chatbot Personalizado com AWS Bedrock
Utilizando AWS Bedrock para Constru√ß√£o de Chat com IA Generativa com Conte√∫dos Incorporados

### üìã Pr√©-requisitos

```
Node v20+
Conta AWS com credenciais configuradas (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION)
Chave de acesso ao Bedrock habilitada
```

### üîß Instala√ß√£o

```
npm install
```

### ‚öôÔ∏è Executando 

No arquivo embedding-generator.ts cont√©m o caminho para o "conteudo.txt" no qual √© o arquivo utilizado para gerar os embeddings a partir do comando abaixo:
```
npm dev:chat-generator
```
Para rodar o Chatbot como um pequeno server para teste, basta executar: 
```Q
npm dev:chat-server
```
## Arquitetura do Projeto

O AWS Bedrock √© um servi√ßo da Amazon que oferece uma variedade de modelos de IA Generativa atrav√©s de uma API unificada. Esses modelos podem automatizar tarefas como sumariza√ß√£o, gera√ß√£o de textos, an√°lise de conte√∫do e muito mais, permitindo a cria√ß√£o de solu√ß√µes inteligentes e altamente personaliz√°veis.

![Diagrama do projeto](assets/aws-bedrock-diagram.png)

### üõ†Ô∏è Constru√≠do com

* [AWS SDK Javascript v3](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/client/lambda/command/InvokeCommand/)
* [LLMs - AWS Bedrock](https://aws.amazon.com/pt/bedrock/)
* [Langchain](https://js.langchain.com/docs/introduction/)

### Explica√ß√£o

O sistema est√° dividido em duas partes principais: Administra√ß√£o e Indexa√ß√£o de Documentos. A primeira parte do sistema √© voltada para a administra√ß√£o, permitindo que documentos espec√≠ficos sejam carregados e processados pelos modelos Titan Embeddings. Esses embeddings fornecem uma representa√ß√£o vetorial dos documentos, capturando o significado do conte√∫do. Os vetores gerados s√£o armazenados no FAISS store integrado ao Langchain, que ser√° usado para realizar consultas r√°pidas e eficientes posteriormente.

Consulta e Gera√ß√£o de Respostas: Na segunda parte, voltada para o usu√°rio final, quando uma pergunta √© feita ao chat, o sistema gera embeddings da consulta utilizando Titan Text Embeddings. Esses embeddings s√£o comparados com os vetores armazenados no FAISS store, que identifica as partes mais relevantes dos documentos. Essas partes relevantes s√£o recuperadas e incorporadas ao contexto (prompt), que ser√° passado para a IA Generativa. Com base nesse contexto, a IA gera uma resposta precisa e relevante. O AWS Bedrock oferece diversos modelos de LLM, proporcionando flexibilidade em termos de desempenho e custo.

### Personaliza√ß√£o e Escalabilidade

Embora a arquitetura seja comum em termos de conceito, ela √© extremamente poderosa. Caso o foco seja em um chatbot, √© poss√≠vel utilizar uma variedade de tipos de arquivos, como PDF, TXT, DOCS, CSV, entre outros, para aumentar a base de conhecimento da IA.

Al√©m disso, a ampla gama de modelos de LLMs dispon√≠veis permite a cria√ß√£o de solu√ß√µes que realizam an√°lises avan√ßadas e detalhadas de documentos, indo al√©m das funcionalidades t√≠picas de um chat simples.

A flexibilidade da arquitetura permite que a solu√ß√£o seja hospedada em ambientes serverless ou em infraestrutura dedicada, como em EC2 ou at√© mesmo utilizando Lambda e API Gateway para uma implementa√ß√£o mais √°gil e escal√°vel.

O conte√∫do utilizado est√° presente na pasta assets `conteudo.txt`, nele cont√©m um pequeno texto fict√≠cio de uma empresa de tecnologia gerado por IA para servir de alimenta√ß√£o para o Chatbot.

Chat:

![Chat](assets/chat.png)